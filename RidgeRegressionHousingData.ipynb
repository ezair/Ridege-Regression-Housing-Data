{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Ridge Regression (interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will run ridge regression multiple times with different L2 penalties to see which one produces the best fit. We will revisit the example of polynomial regression as a means to see the effect of L2 regularization. In particular, we will:\n",
    "* Use a pre-built implementation of regression (Turi Create) to run polynomial regression\n",
    "* Use matplotlib to visualize polynomial regressions\n",
    "* Use a pre-built implementation of regression (Turi Create) to run polynomial regression, this time with L2 penalty\n",
    "* Use matplotlib to visualize polynomial regressions under L2 regularization\n",
    "* Choose best L2 penalty using cross-validation.\n",
    "* Assess the final fit using test data.\n",
    "\n",
    "We will continue to use the House data from previous notebooks.  (In the next programming assignment for this module, you will implement your own ridge regression learning algorithm using gradient descent.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up Turi Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turicreate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial regression, revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build on the material from Week 3, where we wrote the function to produce an SFrame with columns containing the powers of a given input. Copy and paste the function `polynomial_sframe` from previous assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_features(data, deg):\n",
    "    data_copy = data.copy()\n",
    "    for i in range(1, deg):\n",
    "        data_copy['X' + str(i + 1)] = data_copy['X' + str(i)] * data_copy['X1']\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use matplotlib to visualize what a polynomial regression looks like on the house data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = turicreate.SFrame('home_data.sframe/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Week 3, we will use the sqft_living variable. For plotting purposes (connecting the dots), you'll need to sort by the values of sqft_living. For houses with identical square footage, we break the tie by their prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales.sort(['sqft_living','price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us revisit the 15th polynomial model using the 'sqft_living' input.Generate polynomial features up to degree 15 using `polynomial_features()`and fit a model with these features. When fitting the model,use an L2 penalty of `1e-5`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_small_penalty = 1e-5\n",
    "x = sales['sqft_living']\n",
    "y = sales['price']\n",
    "data_frame = turicreate.SFrame({'X1': x})\n",
    "data_frame = data_frame.add_column(y, column_name='price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: When we have so many features and so few data points, the solution can become highly numerically unstable, which can sometimes lead to strange unpredictable results.  Thus, rather than using no regularization, we will introduce a tiny amount of regularization (`l2_penalty=1e-5`) to make the solution numerically stable.  (In lecture, we discussed the fact that regularization can also help with numerical stability, and here we are seeing a practical example.)\n",
    "\n",
    "With the L2 penalty specified above, fit the model and print out the learned weights.\n",
    "\n",
    "Hint: make sure to add 'price' column to the new SFrame before calling `turicreate.linear_regression.create()`. Also, make sure Turi Create doesn't create its own validation set by using the option `validation_set=None` in this call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Class                          : LinearRegression\n\nSchema\n------\nNumber of coefficients         : 16\nNumber of examples             : 21613\nNumber of feature columns      : 15\nNumber of unpacked features    : 15\n\nHyperparameters\n---------------\nL1 penalty                     : 0.0\nL2 penalty                     : 0.0\n\nTraining Summary\n----------------\nSolver                         : newton\nSolver iterations              : 1\nSolver status                  : SUCCESS: Optimal solution found.\nTraining time (sec)            : 0.0344\n\nSettings\n--------\nResidual sum of squares        : 1304281816164108.0\nTraining RMSE                  : 245656.4622\n\nHighest Positive Coefficients\n-----------------------------\n(intercept)                    : 167924.8706\nX1                             : 103.0909\nX2                             : 0.1346\nX4                             : 0.0\nX6                             : 0.0\n\nLowest Negative Coefficients\n----------------------------\nX3                             : -0.0001\nX5                             : -0.0\nX8                             : -0.0\nX9                             : -0.0\nX10                            : -0.0\n\n"
    }
   ],
   "source": [
    "def polynomial_regression(data, deg, l2_penalty, validation_set=None):\n",
    "    model = turicreate.linear_regression.create(polynomial_features(data, deg),\n",
    "                                                target='price',\n",
    "                                                l2_penalty=l2_penalty,\n",
    "                                                l1_penalty=0.,\n",
    "                                                validation_set=validation_set,\n",
    "                                                verbose=False)    \n",
    "    \n",
    "    return model\n",
    "\n",
    "model = polynomial_regression(data=data_frame, deg=15, l2_penalty=l2_small_penalty)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION:  What's the learned value for the coefficient of feature `power_1`?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learned rate of coeficient 1\n",
    "\n",
    "X1 : 103.0909"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observe overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from Week 3 that the polynomial fit of degree 15 changed wildly whenever the data changed. In particular, when we split the sales data into four subsets and fit the model of degree 15, the result came out to be very different for each subset. The model had a *high variance*. We will see in a moment that ridge regression reduces such variance. But first, we must reproduce the experiment we did in Week 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, split the data into split the sales data into four subsets of roughly equal size and call them `set_1`, `set_2`, `set_3`, and `set_4`. Use `.random_split` function and make sure you set `seed=0`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {},
   "outputs": [],
   "source": [
    "(semi_split1, semi_split2) = sales.random_split(.5,seed=0)\n",
    "(set_1, set_2) = semi_split1.random_split(0.5, seed=0)\n",
    "(set_3, set_4) = semi_split2.random_split(0.5, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, fit a 15th degree polynomial on `set_1`, `set_2`, `set_3`, and `set_4`, using 'sqft_living' to predict prices. Print the weights and make a plot of the resulting model.\n",
    "\n",
    "Hint: When calling `turicreate.linear_regression.create()`, use the same L2 penalty as before (i.e. `l2_small_penalty`).  Also, make sure Turi Create doesn't create its own validation set by using the option `validation_set = None` in this call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Class                          : LinearRegression\n\nSchema\n------\nNumber of coefficients         : 16\nNumber of examples             : 5404\nNumber of feature columns      : 15\nNumber of unpacked features    : 15\n\nHyperparameters\n---------------\nL1 penalty                     : 0.0\nL2 penalty                     : 0.0\n\nTraining Summary\n----------------\nSolver                         : newton\nSolver iterations              : 1\nSolver status                  : SUCCESS: Optimal solution found.\nTraining time (sec)            : 0.0046\n\nSettings\n--------\nResidual sum of squares        : 334244159982603.5\nTraining RMSE                  : 248699.1173\n\nHighest Positive Coefficients\n-----------------------------\n(intercept)                    : 9306.4651\nX1                             : 585.8658\nX3                             : 0.0001\nX6                             : 0.0\nX7                             : 0.0\n\nLowest Negative Coefficients\n----------------------------\nX2                             : -0.3973\nX4                             : -0.0\nX5                             : -0.0\nX9                             : -0.0\nX10                            : -0.0\n\n"
    }
   ],
   "source": [
    "x = set_1['sqft_living']\n",
    "y = set_1['price']\n",
    "data_frame = turicreate.SFrame({'X1': x})\n",
    "data_frame = data_frame.add_column(y, column_name='price')\n",
    "\n",
    "set_1_model = polynomial_regression(data_frame, 15, l2_penalty=l2_small_penalty)\n",
    "print(set_1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Class                          : LinearRegression\n\nSchema\n------\nNumber of coefficients         : 16\nNumber of examples             : 5398\nNumber of feature columns      : 15\nNumber of unpacked features    : 15\n\nHyperparameters\n---------------\nL1 penalty                     : 0.0\nL2 penalty                     : 0.0\n\nTraining Summary\n----------------\nSolver                         : newton\nSolver iterations              : 1\nSolver status                  : SUCCESS: Optimal solution found.\nTraining time (sec)            : 0.0047\n\nSettings\n--------\nResidual sum of squares        : 296922466397560.1\nTraining RMSE                  : 234533.6106\n\nHighest Positive Coefficients\n-----------------------------\nX1                             : 783.4938\nX3                             : 0.0004\nX5                             : 0.0\nX6                             : 0.0\nX10                            : 0.0\n\nLowest Negative Coefficients\n----------------------------\n(intercept)                    : -25115.8972\nX2                             : -0.7678\nX4                             : -0.0\nX7                             : -0.0\nX8                             : -0.0\n\n"
    }
   ],
   "source": [
    "x = set_2['sqft_living']\n",
    "y = set_2['price']\n",
    "data_frame = turicreate.SFrame({'X1': x})\n",
    "data_frame = data_frame.add_column(y, column_name='price')\n",
    "\n",
    "set_2_model = polynomial_regression(data_frame, 15, l2_penalty=l2_small_penalty)\n",
    "print(set_2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Class                          : LinearRegression\n\nSchema\n------\nNumber of coefficients         : 16\nNumber of examples             : 5409\nNumber of feature columns      : 15\nNumber of unpacked features    : 15\n\nHyperparameters\n---------------\nL1 penalty                     : 0.0\nL2 penalty                     : 0.0\n\nTraining Summary\n----------------\nSolver                         : newton\nSolver iterations              : 1\nSolver status                  : SUCCESS: Optimal solution found.\nTraining time (sec)            : 0.0093\n\nSettings\n--------\nResidual sum of squares        : 341037823457605.44\nTraining RMSE                  : 251097.7281\n\nHighest Positive Coefficients\n-----------------------------\n(intercept)                    : 462426.5778\nX2                             : 1.0287\nX4                             : 0.0\nX7                             : 0.0\nX8                             : 0.0\n\nLowest Negative Coefficients\n----------------------------\nX1                             : -759.2519\nX3                             : -0.0005\nX5                             : -0.0\nX6                             : -0.0\nX10                            : -0.0\n\n"
    }
   ],
   "source": [
    "x = set_3['sqft_living']\n",
    "y = set_3['price']\n",
    "data_frame = turicreate.SFrame({'X1': x})\n",
    "data_frame = data_frame.add_column(y, column_name='price')\n",
    "\n",
    "set_3_model = polynomial_regression(data_frame, 15, l2_penalty=l2_small_penalty)\n",
    "print(set_3_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Class                          : LinearRegression\n\nSchema\n------\nNumber of coefficients         : 16\nNumber of examples             : 5402\nNumber of feature columns      : 15\nNumber of unpacked features    : 15\n\nHyperparameters\n---------------\nL1 penalty                     : 0.0\nL2 penalty                     : 0.0\n\nTraining Summary\n----------------\nSolver                         : newton\nSolver iterations              : 1\nSolver status                  : SUCCESS: Optimal solution found.\nTraining time (sec)            : 0.0078\n\nSettings\n--------\nResidual sum of squares        : 322513810180898.75\nTraining RMSE                  : 244341.2932\n\nHighest Positive Coefficients\n-----------------------------\nX1                             : 1247.5904\nX3                             : 0.0006\nX6                             : 0.0\nX7                             : 0.0\nX10                            : 0.0\n\nLowest Negative Coefficients\n----------------------------\n(intercept)                    : -170240.036\nX2                             : -1.2246\nX4                             : -0.0\nX5                             : -0.0\nX8                             : -0.0\n\n"
    }
   ],
   "source": [
    "x = set_4['sqft_living']\n",
    "y = set_4['price']\n",
    "data_frame = turicreate.SFrame({'X1': x})\n",
    "data_frame = data_frame.add_column(y, column_name='price')\n",
    "\n",
    "set_4_model = polynomial_regression(data_frame, 15, l2_penalty=l2_small_penalty)\n",
    "print(set_4_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four curves should differ from one another a lot, as should the coefficients you learned.\n",
    "\n",
    "***QUIZ QUESTION:  For the models learned in each of these training sets, what are the smallest and largest values you learned for the coefficient of feature `power_1`?***  (For the purpose of answering this question, negative numbers are considered \"smaller\" than positive numbers. So -5 is smaller than -3, and -3 is smaller than 5 and so forth.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smallest Value\n",
    "\n",
    "X1: -759.2519 from the model created on the 3rd set.\n",
    "\n",
    "### Largest Value\n",
    "X1 : 1247.5904 from the model created on the 4th set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, whenever we see weights change so much in response to change in data, we believe the variance of our estimate to be large. Ridge regression aims to address this issue by penalizing \"large\" weights. (Weights of `model15` looked quite small, but they are not that small because 'sqft_living' input is in the order of thousands.)\n",
    "\n",
    "With the argument `l2_penalty=1e5`, fit a 15th-order polynomial model on `set_1`, `set_2`, `set_3`, and `set_4`. Other than the change in the `l2_penalty` parameter, the code should be the same as the experiment above. Also, make sure Turi Create doesn't create its own validation set by using the option `validation_set = None` in this call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression comes to rescue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Class                          : LinearRegression\n\nSchema\n------\nNumber of coefficients         : 16\nNumber of examples             : 5402\nNumber of feature columns      : 15\nNumber of unpacked features    : 15\n\nHyperparameters\n---------------\nL1 penalty                     : 0.0\nL2 penalty                     : 100000.0\n\nTraining Summary\n----------------\nSolver                         : newton\nSolver iterations              : 1\nSolver status                  : SUCCESS: Optimal solution found.\nTraining time (sec)            : 0.0082\n\nSettings\n--------\nResidual sum of squares        : 563974715173920.4\nTraining RMSE                  : 323111.5829\n\nHighest Positive Coefficients\n-----------------------------\n(intercept)                    : 513667.0871\nX1                             : 1.9104\nX2                             : 0.0011\nX3                             : 0.0\nX4                             : 0.0\n\nLowest Negative Coefficients\n----------------------------\nNo Negative Coefficients       : \n\n"
    }
   ],
   "source": [
    "\n",
    "data_frame = turicreate.SFrame({'X1': x})\n",
    "data_frame = data_frame.add_column(y, column_name='price')\n",
    "set_1_model = polynomial_regression(data_frame, 15, l2_penalty=1e5)\n",
    "print(set_1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Class                          : LinearRegression\n\nSchema\n------\nNumber of coefficients         : 16\nNumber of examples             : 5398\nNumber of feature columns      : 15\nNumber of unpacked features    : 15\n\nHyperparameters\n---------------\nL1 penalty                     : 0.0\nL2 penalty                     : 100000.0\n\nTraining Summary\n----------------\nSolver                         : newton\nSolver iterations              : 1\nSolver status                  : SUCCESS: Optimal solution found.\nTraining time (sec)            : 0.0047\n\nSettings\n--------\nResidual sum of squares        : 564001004832112.1\nTraining RMSE                  : 323238.8096\n\nHighest Positive Coefficients\n-----------------------------\n(intercept)                    : 519216.8974\nX1                             : 2.0447\nX2                             : 0.0011\nX3                             : 0.0\nX4                             : 0.0\n\nLowest Negative Coefficients\n----------------------------\nNo Negative Coefficients       : \n\n"
    }
   ],
   "source": [
    "x = set_2['sqft_living']\n",
    "y = set_2['price']\n",
    "data_frame = turicreate.SFrame({'X1': x})\n",
    "data_frame = data_frame.add_column(y, column_name='price')\n",
    "\n",
    "set_2_model = polynomial_regression(data_frame, 15, l2_penalty=1e5)\n",
    "print(set_2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Class                          : LinearRegression\n\nSchema\n------\nNumber of coefficients         : 16\nNumber of examples             : 5409\nNumber of feature columns      : 15\nNumber of unpacked features    : 15\n\nHyperparameters\n---------------\nL1 penalty                     : 0.0\nL2 penalty                     : 100000.0\n\nTraining Summary\n----------------\nSolver                         : newton\nSolver iterations              : 1\nSolver status                  : SUCCESS: Optimal solution found.\nTraining time (sec)            : 0.0084\n\nSettings\n--------\nResidual sum of squares        : 662729427751762.8\nTraining RMSE                  : 350033.5213\n\nHighest Positive Coefficients\n-----------------------------\n(intercept)                    : 522911.518\nX1                             : 2.2689\nX2                             : 0.0013\nX3                             : 0.0\nX4                             : 0.0\n\nLowest Negative Coefficients\n----------------------------\nNo Negative Coefficients       : \n\n"
    }
   ],
   "source": [
    "x = set_3['sqft_living']\n",
    "y = set_3['price']\n",
    "data_frame = turicreate.SFrame({'X1': x})\n",
    "data_frame = data_frame.add_column(y, column_name='price')\n",
    "\n",
    "set_3_model = polynomial_regression(data_frame, 15, l2_penalty=1e5)\n",
    "print(set_3_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Class                          : LinearRegression\n\nSchema\n------\nNumber of coefficients         : 16\nNumber of examples             : 5402\nNumber of feature columns      : 15\nNumber of unpacked features    : 15\n\nHyperparameters\n---------------\nL1 penalty                     : 0.0\nL2 penalty                     : 100000.0\n\nTraining Summary\n----------------\nSolver                         : newton\nSolver iterations              : 1\nSolver status                  : SUCCESS: Optimal solution found.\nTraining time (sec)            : 0.0077\n\nSettings\n--------\nResidual sum of squares        : 563974715173920.4\nTraining RMSE                  : 323111.5829\n\nHighest Positive Coefficients\n-----------------------------\n(intercept)                    : 513667.0871\nX1                             : 1.9104\nX2                             : 0.0011\nX3                             : 0.0\nX4                             : 0.0\n\nLowest Negative Coefficients\n----------------------------\nNo Negative Coefficients       : \n\n"
    }
   ],
   "source": [
    "x = set_4['sqft_living']\n",
    "y = set_4['price']\n",
    "data_frame = turicreate.SFrame({'X1': x})\n",
    "data_frame = data_frame.add_column(y, column_name='price')\n",
    "\n",
    "set_4_model = polynomial_regression(data_frame, 15, l2_penalty=1e5)\n",
    "print(set_4_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These curves should vary a lot less, now that you applied a high degree of regularization.\n",
    "\n",
    "***QUIZ QUESTION:  For the models learned with the high level of regularization in each of these training sets, what are the smallest and largest values you learned for the coefficient of feature `power_1`?*** (For the purpose of answering this question, negative numbers are considered \"smaller\" than positive numbers. So -5 is smaller than -3, and -3 is smaller than 5 and so forth.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Largest\n",
    "\n",
    "The largest was X1: 2.26  in set 1.\n",
    "\n",
    "### Smallest\n",
    "\n",
    "The smallest was X1:1.91 in set 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting an L2 penalty via cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the polynomial degree, the L2 penalty is a \"magic\" parameter we need to select. We could use the validation set approach as we did in the last module, but that approach has a major disadvantage: it leaves fewer observations available for training. **Cross-validation** seeks to overcome this issue by using all of the training set in a smart way.\n",
    "\n",
    "We will implement a kind of cross-validation called **k-fold cross-validation**. The method gets its name because it involves dividing the training set into k segments of roughtly equal size. Similar to the validation set method, we measure the validation error with one of the segments designated as the validation set. The major difference is that we repeat the process k times as follows:\n",
    "\n",
    "Set aside segment 0 as the validation set, and fit a model on rest of data, and evalutate it on this validation set<br>\n",
    "Set aside segment 1 as the validation set, and fit a model on rest of data, and evalutate it on this validation set<br>\n",
    "...<br>\n",
    "Set aside segment k-1 as the validation set, and fit a model on rest of data, and evalutate it on this validation set\n",
    "\n",
    "After this process, we compute the average of the k validation errors, and use it as an estimate of the generalization error. Notice that  all observations are used for both training and validation, as we iterate over segments of data. \n",
    "\n",
    "To estimate the generalization error well, it is crucial to shuffle the training data before dividing them into segments. The package turicreate_cross_validation (see below) has a utility function for shuffling a given SFrame. We reserve 10% of the data as the test set and shuffle the remainder. (Make sure to use `seed=1` to get consistent answer.)\n",
    "\n",
    "  \n",
    "_Note:_ For applying cross-validation, we will import a package called `turicreate_cross_validation`. To install it, please run this command on your terminal:\n",
    "\n",
    "`pip install -e git+https://github.com/Kagandi/turicreate-cross-validation.git#egg=turicreate_cross_validation`\n",
    "\n",
    "You can find the documentation on this package here: https://github.com/Kagandi/turicreate-cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turicreate_cross_validation.cross_validation as tcv\n",
    "\n",
    "(train_valid, test) = sales.random_split(.9, seed=1)\n",
    "train_valid_shuffled = tcv.shuffle_sframe(train_valid, random_seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is shuffled, we divide it into equal segments. Each segment should receive `n/k` elements, where `n` is the number of observations in the training set and `k` is the number of segments. Since the segment 0 starts at index 0 and contains `n/k` elements, it ends at index `(n/k)-1`. The segment 1 starts where the segment 0 left off, at index `(n/k)`. With `n/k` elements, the segment 1 ends at index `(n*2/k)-1`. Continuing in this fashion, we deduce that the segment `i` starts at index `(n*i/k)` and ends at `(n*(i+1)/k)-1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this pattern in mind, we write a short loop that prints the starting and ending indices of each segment, just to make sure you are getting the splits right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 (0.0, 1938.6)\n1 (1939.6, 3878.2)\n2 (3879.2, 5817.8)\n3 (5818.8, 7757.4)\n4 (7758.4, 9697.0)\n5 (9698.0, 11636.6)\n6 (11637.6, 13576.2)\n7 (13577.2, 15515.8)\n8 (15516.8, 17455.4)\n9 (17456.4, 19395.0)\n"
    }
   ],
   "source": [
    "n = len(train_valid_shuffled)\n",
    "k = 10 # 10-fold cross-validation\n",
    "\n",
    "for i in range(k):\n",
    "    start = (n*i)/k\n",
    "    end = (n*(i+1))/k-1\n",
    "    print(i, (start, end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us familiarize ourselves with array slicing with SFrame. To extract a continuous slice from an SFrame, use colon in square brackets. For instance, the following cell extracts rows 0 to 9 of `train_valid_shuffled`. Notice that the first index (0) is included in the slice but the last index (10) is omitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Columns:\n\tid\tstr\n\tdate\tdatetime\n\tprice\tfloat\n\tbedrooms\tfloat\n\tbathrooms\tfloat\n\tsqft_living\tfloat\n\tsqft_lot\tfloat\n\tfloors\tfloat\n\twaterfront\tint\n\tview\tint\n\tcondition\tint\n\tgrade\tfloat\n\tsqft_above\tfloat\n\tsqft_basement\tfloat\n\tyr_built\tfloat\n\tyr_renovated\tfloat\n\tzipcode\tstr\n\tlat\tfloat\n\tlong\tfloat\n\tsqft_living15\tfloat\n\tsqft_lot15\tfloat\n\nRows: 10\n\nData:\n+------------+---------------------------+-----------+----------+-----------+\n|     id     |            date           |   price   | bedrooms | bathrooms |\n+------------+---------------------------+-----------+----------+-----------+\n| 8645511350 | 2014-12-01 00:00:00+00:00 |  300000.0 |   3.0    |    1.75   |\n| 7237501370 | 2014-07-17 00:00:00+00:00 | 1079000.0 |   4.0    |    3.25   |\n| 7278700100 | 2015-01-21 00:00:00+00:00 |  625000.0 |   4.0    |    2.5    |\n| 1421079007 | 2015-03-24 00:00:00+00:00 |  408506.0 |   3.0    |    2.75   |\n| 4338800370 | 2014-11-17 00:00:00+00:00 |  220000.0 |   3.0    |    1.0    |\n| 7511200020 | 2014-08-29 00:00:00+00:00 |  509900.0 |   3.0    |    1.75   |\n| 3300701615 | 2014-09-30 00:00:00+00:00 |  655000.0 |   4.0    |    2.5    |\n| 7011200260 | 2014-12-19 00:00:00+00:00 |  485000.0 |   4.0    |    2.0    |\n| 3570000130 | 2014-06-11 00:00:00+00:00 |  580379.0 |   4.0    |    2.75   |\n| 2796100640 | 2015-04-24 00:00:00+00:00 |  264900.0 |   4.0    |    2.5    |\n+------------+---------------------------+-----------+----------+-----------+\n+-------------+----------+--------+------------+------+-----------+-------+\n| sqft_living | sqft_lot | floors | waterfront | view | condition | grade |\n+-------------+----------+--------+------------+------+-----------+-------+\n|    1810.0   | 21138.0  |  1.0   |     0      |  0   |     4     |  7.0  |\n|    4800.0   | 12727.0  |  2.0   |     0      |  0   |     3     |  10.0 |\n|    2740.0   |  9599.0  |  1.0   |     0      |  2   |     3     |  8.0  |\n|    2480.0   | 209199.0 |  1.5   |     0      |  0   |     3     |  8.0  |\n|    1000.0   |  6020.0  |  1.0   |     0      |  0   |     3     |  6.0  |\n|    1690.0   | 53578.0  |  1.0   |     0      |  0   |     3     |  8.0  |\n|    2630.0   |  4000.0  |  3.0   |     0      |  0   |     3     |  8.0  |\n|    1400.0   |  3600.0  |  1.0   |     0      |  0   |     3     |  7.0  |\n|    2240.0   | 27820.0  |  1.5   |     0      |  0   |     4     |  8.0  |\n|    2040.0   |  7000.0  |  1.0   |     0      |  0   |     3     |  7.0  |\n+-------------+----------+--------+------------+------+-----------+-------+\n+------------+---------------+----------+--------------+---------+-------------+\n| sqft_above | sqft_basement | yr_built | yr_renovated | zipcode |     lat     |\n+------------+---------------+----------+--------------+---------+-------------+\n|   1240.0   |     570.0     |  1977.0  |     0.0      |  98058  | 47.46736904 |\n|   4800.0   |      0.0      |  2011.0  |     0.0      |  98059  | 47.53108576 |\n|   1820.0   |     920.0     |  1961.0  |     0.0      |  98177  | 47.77279701 |\n|   1870.0   |     610.0     |  2000.0  |     0.0      |  98010  | 47.30847072 |\n|   1000.0   |      0.0      |  1944.0  |     0.0      |  98166  | 47.47933643 |\n|   1690.0   |      0.0      |  1984.0  |     0.0      |  98053  |  47.6545751 |\n|   2630.0   |      0.0      |  2002.0  |     0.0      |  98117  | 47.69151411 |\n|   1100.0   |     300.0     |  1900.0  |     0.0      |  98119  | 47.63846783 |\n|   2240.0   |      0.0      |  1976.0  |     0.0      |  98075  | 47.59357299 |\n|   1250.0   |     790.0     |  1979.0  |     0.0      |  98031  | 47.40555074 |\n+------------+---------------+----------+--------------+---------+-------------+\n+---------------+---------------+-----+\n|      long     | sqft_living15 | ... |\n+---------------+---------------+-----+\n| -122.17768631 |     1850.0    | ... |\n| -122.13389261 |     4750.0    | ... |\n| -122.38485302 |     2660.0    | ... |\n| -121.88816296 |     2040.0    | ... |\n| -122.34575463 |     1300.0    | ... |\n| -122.04899568 |     2290.0    | ... |\n| -122.38139901 |     1640.0    | ... |\n| -122.36993806 |     1630.0    | ... |\n| -122.05362447 |     2330.0    | ... |\n| -122.17648783 |     1900.0    | ... |\n+---------------+---------------+-----+\n[10 rows x 21 columns]",
      "text/html": "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n    <tr>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">id</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">date</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">price</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">bedrooms</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">bathrooms</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sqft_living</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sqft_lot</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">floors</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">waterfront</th>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8645511350</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2014-12-01 00:00:00+00:00</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">300000.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.75</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1810.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">21138.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7237501370</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2014-07-17 00:00:00+00:00</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1079000.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.25</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4800.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">12727.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7278700100</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2015-01-21 00:00:00+00:00</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">625000.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.5</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2740.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9599.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1421079007</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2015-03-24 00:00:00+00:00</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">408506.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.75</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2480.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">209199.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.5</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4338800370</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2014-11-17 00:00:00+00:00</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">220000.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1000.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6020.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7511200020</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2014-08-29 00:00:00+00:00</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">509900.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.75</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1690.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">53578.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3300701615</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2014-09-30 00:00:00+00:00</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">655000.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.5</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2630.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4000.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7011200260</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2014-12-19 00:00:00+00:00</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">485000.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1400.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3600.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3570000130</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2014-06-11 00:00:00+00:00</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">580379.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.75</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2240.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">27820.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.5</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2796100640</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2015-04-24 00:00:00+00:00</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">264900.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.5</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2040.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7000.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n    </tr>\n</table>\n<table frame=\"box\" rules=\"cols\">\n    <tr>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">view</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">condition</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">grade</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sqft_above</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sqft_basement</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">yr_built</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">yr_renovated</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">zipcode</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">lat</th>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1240.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">570.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1977.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98058</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.46736904</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4800.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2011.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98059</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.53108576</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1820.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">920.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1961.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98177</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.77279701</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1870.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">610.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2000.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98010</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.30847072</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1000.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1944.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98166</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.47933643</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1690.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1984.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98053</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.6545751</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2630.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2002.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98117</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.69151411</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1100.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">300.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1900.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98119</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.63846783</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2240.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1976.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98075</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.59357299</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1250.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">790.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1979.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">98031</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">47.40555074</td>\n    </tr>\n</table>\n<table frame=\"box\" rules=\"cols\">\n    <tr>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">long</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sqft_living15</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sqft_lot15</th>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.17768631</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1850.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">12200.0</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.13389261</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4750.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">13602.0</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.38485302</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2660.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8280.0</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-121.88816296</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2040.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">219229.0</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.34575463</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1300.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8640.0</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.04899568</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2290.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">52707.0</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.38139901</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1640.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4000.0</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.36993806</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1630.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2048.0</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.05362447</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2330.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">20000.0</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-122.17648783</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1900.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7378.0</td>\n    </tr>\n</table>\n[10 rows x 21 columns]<br/>\n</div>"
     },
     "metadata": {},
     "execution_count": 1098
    }
   ],
   "source": [
    "train_valid_shuffled[0:10] # rows 0 to 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us extract individual segments with array slicing. Consider the scenario where we group the houses in the `train_valid_shuffled` dataframe into k=10 segments of roughly equal size, with starting and ending indices computed as above.\n",
    "Extract the fourth segment (segment 3) and assign it to a variable called `validation4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Return a k data set between 1 and k.\n",
    "Used for splitting sets up for X-validation.\n",
    "param: data_set -- Data set that is split into k sets.\n",
    "param: k -- The amount of sets to split data_set into.\n",
    "param: segment_number: The k data set that you want.\n",
    "Returns a k data set\"\"\"\n",
    "def extract_k_set(data_set, k, segment_number):\n",
    "    i = segment_number - 1\n",
    "    n = len(data_set)\n",
    "    starting_index = n * i / k\n",
    "    ending_index = n * (i + 1) / k - 1\n",
    "    return data_set[starting_index: ending_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation4 = extract_k_set(train_valid_shuffled, k, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify that we have the right elements extracted, run the following cell, which computes the average price of the fourth segment. When rounded to nearest whole number, the average should be $559,642."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "559642\n"
    }
   ],
   "source": [
    "print(int(round(validation4['price'].mean(), 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After designating one of the k segments as the validation set, we train a model using the rest of the data. To choose the remainder, we slice (0:start) and (end+1:n) of the data and paste them together. SFrame has `append()` method that pastes together two disjoint sets of rows originating from a common dataset. For instance, the following cell pastes together the first and last two rows of the `train_valid_shuffled` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+------------+---------------------------+-----------+----------+-----------+\n|     id     |            date           |   price   | bedrooms | bathrooms |\n+------------+---------------------------+-----------+----------+-----------+\n| 8645511350 | 2014-12-01 00:00:00+00:00 |  300000.0 |   3.0    |    1.75   |\n| 7237501370 | 2014-07-17 00:00:00+00:00 | 1079000.0 |   4.0    |    3.25   |\n| 4077800582 | 2014-09-12 00:00:00+00:00 |  522000.0 |   3.0    |    1.0    |\n| 7853370620 | 2015-02-06 00:00:00+00:00 |  605000.0 |   5.0    |    4.0    |\n+------------+---------------------------+-----------+----------+-----------+\n+-------------+----------+--------+------------+------+-----------+-------+\n| sqft_living | sqft_lot | floors | waterfront | view | condition | grade |\n+-------------+----------+--------+------------+------+-----------+-------+\n|    1810.0   | 21138.0  |  1.0   |     0      |  0   |     4     |  7.0  |\n|    4800.0   | 12727.0  |  2.0   |     0      |  0   |     3     |  10.0 |\n|    1150.0   |  7080.0  |  1.0   |     0      |  0   |     3     |  7.0  |\n|    3040.0   |  6000.0  |  2.0   |     0      |  0   |     3     |  8.0  |\n+-------------+----------+--------+------------+------+-----------+-------+\n+------------+---------------+----------+--------------+---------+-------------+\n| sqft_above | sqft_basement | yr_built | yr_renovated | zipcode |     lat     |\n+------------+---------------+----------+--------------+---------+-------------+\n|   1240.0   |     570.0     |  1977.0  |     0.0      |  98058  | 47.46736904 |\n|   4800.0   |      0.0      |  2011.0  |     0.0      |  98059  | 47.53108576 |\n|   1150.0   |      0.0      |  1952.0  |     0.0      |  98125  | 47.71063854 |\n|   2280.0   |     760.0     |  2011.0  |     0.0      |  98065  | 47.51887717 |\n+------------+---------------+----------+--------------+---------+-------------+\n+---------------+---------------+-----+\n|      long     | sqft_living15 | ... |\n+---------------+---------------+-----+\n| -122.17768631 |     1850.0    | ... |\n| -122.13389261 |     4750.0    | ... |\n| -122.28837299 |     1490.0    | ... |\n| -121.87558112 |     3070.0    | ... |\n+---------------+---------------+-----+\n[4 rows x 21 columns]\n\n"
    }
   ],
   "source": [
    "n = len(train_valid_shuffled)\n",
    "first_two = train_valid_shuffled[0:2]\n",
    "last_two = train_valid_shuffled[n-2:n]\n",
    "print(first_two.append(last_two))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the remainder of the data after *excluding* fourth segment (segment 3) and assign the subset to `train4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "N: 19396\nstarting index: 5818.8\nending index: 7757.4\n533153.0\n+------------+---------------------------+-----------+----------+-----------+\n|     id     |            date           |   price   | bedrooms | bathrooms |\n+------------+---------------------------+-----------+----------+-----------+\n| 8645511350 | 2014-12-01 00:00:00+00:00 |  300000.0 |   3.0    |    1.75   |\n| 7237501370 | 2014-07-17 00:00:00+00:00 | 1079000.0 |   4.0    |    3.25   |\n| 7278700100 | 2015-01-21 00:00:00+00:00 |  625000.0 |   4.0    |    2.5    |\n| 1421079007 | 2015-03-24 00:00:00+00:00 |  408506.0 |   3.0    |    2.75   |\n| 4338800370 | 2014-11-17 00:00:00+00:00 |  220000.0 |   3.0    |    1.0    |\n| 7511200020 | 2014-08-29 00:00:00+00:00 |  509900.0 |   3.0    |    1.75   |\n| 3300701615 | 2014-09-30 00:00:00+00:00 |  655000.0 |   4.0    |    2.5    |\n| 7011200260 | 2014-12-19 00:00:00+00:00 |  485000.0 |   4.0    |    2.0    |\n| 3570000130 | 2014-06-11 00:00:00+00:00 |  580379.0 |   4.0    |    2.75   |\n| 2796100640 | 2015-04-24 00:00:00+00:00 |  264900.0 |   4.0    |    2.5    |\n+------------+---------------------------+-----------+----------+-----------+\n+-------------+----------+--------+------------+------+-----------+-------+\n| sqft_living | sqft_lot | floors | waterfront | view | condition | grade |\n+-------------+----------+--------+------------+------+-----------+-------+\n|    1810.0   | 21138.0  |  1.0   |     0      |  0   |     4     |  7.0  |\n|    4800.0   | 12727.0  |  2.0   |     0      |  0   |     3     |  10.0 |\n|    2740.0   |  9599.0  |  1.0   |     0      |  2   |     3     |  8.0  |\n|    2480.0   | 209199.0 |  1.5   |     0      |  0   |     3     |  8.0  |\n|    1000.0   |  6020.0  |  1.0   |     0      |  0   |     3     |  6.0  |\n|    1690.0   | 53578.0  |  1.0   |     0      |  0   |     3     |  8.0  |\n|    2630.0   |  4000.0  |  3.0   |     0      |  0   |     3     |  8.0  |\n|    1400.0   |  3600.0  |  1.0   |     0      |  0   |     3     |  7.0  |\n|    2240.0   | 27820.0  |  1.5   |     0      |  0   |     4     |  8.0  |\n|    2040.0   |  7000.0  |  1.0   |     0      |  0   |     3     |  7.0  |\n+-------------+----------+--------+------------+------+-----------+-------+\n+------------+---------------+----------+--------------+---------+-------------+\n| sqft_above | sqft_basement | yr_built | yr_renovated | zipcode |     lat     |\n+------------+---------------+----------+--------------+---------+-------------+\n|   1240.0   |     570.0     |  1977.0  |     0.0      |  98058  | 47.46736904 |\n|   4800.0   |      0.0      |  2011.0  |     0.0      |  98059  | 47.53108576 |\n|   1820.0   |     920.0     |  1961.0  |     0.0      |  98177  | 47.77279701 |\n|   1870.0   |     610.0     |  2000.0  |     0.0      |  98010  | 47.30847072 |\n|   1000.0   |      0.0      |  1944.0  |     0.0      |  98166  | 47.47933643 |\n|   1690.0   |      0.0      |  1984.0  |     0.0      |  98053  |  47.6545751 |\n|   2630.0   |      0.0      |  2002.0  |     0.0      |  98117  | 47.69151411 |\n|   1100.0   |     300.0     |  1900.0  |     0.0      |  98119  | 47.63846783 |\n|   2240.0   |      0.0      |  1976.0  |     0.0      |  98075  | 47.59357299 |\n|   1250.0   |     790.0     |  1979.0  |     0.0      |  98031  | 47.40555074 |\n+------------+---------------+----------+--------------+---------+-------------+\n+---------------+---------------+-----+\n|      long     | sqft_living15 | ... |\n+---------------+---------------+-----+\n| -122.17768631 |     1850.0    | ... |\n| -122.13389261 |     4750.0    | ... |\n| -122.38485302 |     2660.0    | ... |\n| -121.88816296 |     2040.0    | ... |\n| -122.34575463 |     1300.0    | ... |\n| -122.04899568 |     2290.0    | ... |\n| -122.38139901 |     1640.0    | ... |\n| -122.36993806 |     1630.0    | ... |\n| -122.05362447 |     2330.0    | ... |\n| -122.17648783 |     1900.0    | ... |\n+---------------+---------------+-----+\n[5818 rows x 21 columns]\nNote: Only the head of the SFrame is printed.\nYou can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n"
    }
   ],
   "source": [
    "segment_number = 3\n",
    "n = len(train_valid_shuffled)\n",
    "starting_index = n * segment_number / k\n",
    "ending_index = n * (segment_number + 1) / k - 1\n",
    "\n",
    "print(f\"N: {n}\")\n",
    "print(f\"starting index: {starting_index}\")\n",
    "print(f\"ending index: {ending_index}\")\n",
    "\n",
    "training_set = train_valid_shuffled[0: 5818]\n",
    "training_set.append(train_valid_shuffled[7758: n])\n",
    "print(round(training_set['price'].mean(), 0))\n",
    "\n",
    "print(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify that we have the right elements extracted, run the following cell, which computes the average price of the data with fourth segment excluded. When rounded to nearest whole number, the average should be $536,865."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "559642\n533153\n"
    }
   ],
   "source": [
    "print(int(round(validation4['price'].mean(), 0)))\n",
    "\n",
    "print(int(round(training_set['price'].mean(), 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to implement k-fold cross-validation. Write a function that computes k validation errors by designating each of the k segments as the validation set. It accepts as parameters (i) `k`, (ii) `l2_penalty`, (iii) dataframe, (iv) name of output column (e.g. `price`) and (v) list of feature names. The function returns the average validation error using k segments as validation sets.\n",
    "\n",
    "* For each i in [0, 1, ..., k-1]:\n",
    "  * Compute starting and ending indices of segment i and call 'start' and 'end'\n",
    "  * Form validation set by taking a slice (start:end+1) from the data.\n",
    "  * Form training set by appending slice (end+1:n) to the end of slice (0:start).\n",
    "  * Train a linear model using training set just formed, with a given l2_penalty\n",
    "  * Compute validation error using validation set just formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(k, l2_penalty_list, data, output_name, features_list, deg):\n",
    "\n",
    "    # Starting and ending indexes for validation set.\n",
    "    def get_starting_ending_indicies(segment_number, n):\n",
    "        starting_index = n * segment_number / k\n",
    "        ending_index = n * (segment_number + 1) / k - 1\n",
    "        return starting_index, ending_index\n",
    "\n",
    "    # Everything that is not in our validation set.\n",
    "    def get_training_set(segment_number, n):\n",
    "        start, end = get_starting_ending_indicies(segment_number=segment_number, n=n)\n",
    "        training_set = data[0: start]\n",
    "        training_set.append(train_valid_shuffled[ending_index + 1: n])\n",
    "        return training_set\n",
    "    \n",
    "    # Return mse a model with the specified params.\n",
    "    def best_l2_from_linear_model(training_data, validation_set, l2_penalty_list,\n",
    "                                  output_name, features_list):\n",
    "\n",
    "        # set x frame to have the proper features_list data.\n",
    "        x = training_data[features_list[0]]\n",
    "        for i in range(1, len(features_list)):\n",
    "            x = training_data[features_list[i]]\n",
    "\n",
    "        # This is the target that we are going to try to predict.\n",
    "        y = training_data[output_name]\n",
    "        \n",
    "        # Now we make the data set that we can pass into our linear reg model.\n",
    "        data_frame = turicreate.SFrame({'X1': x})\n",
    "        data_frame = data_frame.add_column(y, column_name=output_name)\n",
    "\n",
    "        # These fields are important for finding the smallest l2_penalty.\n",
    "        smallest_mse = None\n",
    "        best_l2_penalty = None\n",
    "        \n",
    "        # Alright, lets make each model on each l2_penalty given.\n",
    "        for l2_penalty in l2_penalty_list:\n",
    "            model = turicreate.linear_regression.create(polynomial_features(data_frame, deg),\n",
    "                                                        target=output_name,\n",
    "                                                        l2_penalty=l2_penalty,\n",
    "                                                        l1_penalty=0.,\n",
    "                                                        validation_set=validation_set,\n",
    "                                                        verbose=False)\n",
    "            predicted_value = model.predict(data)\n",
    "            print(predicted_value)\n",
    "\n",
    "            # We will take whatever the smallest mse is.\n",
    "\n",
    "            # Update best_l2_penalty based on the mse value.\n",
    "\n",
    "            exit()\n",
    "\n",
    "    n = len(data)\n",
    "\n",
    "    # The smallest mse means we found the best l2_penalty :)\n",
    "    best_l2_penalty = 0.0\n",
    "\n",
    "    for i in range(1, k - 1):\n",
    "        # We need to find our indexes so we can get a k set from the current segment we are on.\n",
    "        start, end = get_starting_ending_indicies(segment_number=i, n=n)\n",
    "\n",
    "        # Let's split the data correctly into validation and training.\n",
    "        validation_set = data[start: end]\n",
    "        training_set = get_training_set(segment_number=i, n=n)\n",
    "        \n",
    "        # Now, let's find the best mse from the given l2 penalties.\n",
    "        l2_penalty= get_mse_from_linear_model(training_data=training_set,\n",
    "                                              validation_set=validation_set,\n",
    "                                              l2_penalty_list=l2_penalty_list,\n",
    "                                              output_name=output_name,\n",
    "                                              features_list=features_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a function to compute the average validation error for a model, we can write a loop to find the model that minimizes the average validation error. Write a loop that does the following:\n",
    "* We will again be aiming to fit a 15th-order polynomial model using the `sqft_living` input\n",
    "* For `l2_penalty` in [10^1, 10^1.5, 10^2, 10^2.5, ..., 10^7] (to get this in Python, you can use this Numpy function: `np.logspace(1, 7, num=13)`.)\n",
    "    * Run 10-fold cross-validation with `l2_penalty`\n",
    "* Report which L2 penalty produced the lowest average validation error.\n",
    "\n",
    "Note: since the degree of the polynomial is now fixed to 15, to make things faster, you should generate polynomial features in advance and re-use them throughout the loop. Make sure to use `train_valid_shuffled` when generating polynomial features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Two SFrames have different number of columns",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/turicreate/data_structures/sframe.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   4040\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcython_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4041\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mSFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_proxy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__proxy__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__proxy__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mcy_sframe.pyx\u001b[0m in \u001b[0;36mturicreate._cython.cy_sframe.UnitySFrameProxy.append\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcy_sframe.pyx\u001b[0m in \u001b[0;36mturicreate._cython.cy_sframe.UnitySFrameProxy.append\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Two SFrames have different number of columns",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1108-4cf75d0f5c27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                         \u001b[0moutput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                         \u001b[0mfeatures_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sqft_living'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                         deg=15)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1105-b98f4e18d71b>\u001b[0m in \u001b[0;36mk_fold_cross_validation\u001b[0;34m(k, l2_penalty_list, data, output_name, features_list, deg)\u001b[0m\n\u001b[1;32m     60\u001b[0m                                   \u001b[0ml2_penalty_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml2_penalty_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                                   \u001b[0moutput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                                   features_list=features_list)\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1105-b98f4e18d71b>\u001b[0m in \u001b[0;36mget_mse_from_linear_model\u001b[0;34m(training_data, validation_set, l2_penalty_list, output_name, features_list)\u001b[0m\n\u001b[1;32m     34\u001b[0m                                                         \u001b[0ml1_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                                                         \u001b[0mvalidation_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                                                         verbose=False)\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;31m# predicted_value = model.predict(data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/turicreate/toolkits/regression/linear_regression.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(dataset, target, features, l2_penalty, l1_penalty, solver, feature_rescaling, convergence_threshold, step_size, lbfgs_memory_level, max_iterations, validation_set, verbose)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mlbfgs_memory_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlbfgs_memory_level\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mmax_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m     )\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/turicreate/toolkits/_supervised_learning.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(dataset, target, model_name, features, validation_set, distributed, verbose, seed, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;31m# Perform error-checking and trim inputs to specified columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;31m# Sample a validation set from the training data if requested\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/turicreate/toolkits/_internal_utils.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(dataset, target, features, validation_set)\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_SFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;31m# Attempt to append the two datasets together to check schema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m         \u001b[0mvalidation_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m# Reduce validation set to requested columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/turicreate/data_structures/sframe.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   4039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4040\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcython_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4041\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mSFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_proxy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__proxy__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__proxy__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4043\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_column_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/turicreate/_cython/context.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_cython_trace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;31m# To hide cython trace, we re-raise from here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;31m# To show the full trace, we do nothing and let exception propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Two SFrames have different number of columns"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "k_fold_cross_validation(k=10,\n",
    "                        l2_penalty_list=np.logspace(1, 7, num=13),\n",
    "                        data=train_valid_shuffled,\n",
    "                        output_name='price',\n",
    "                        features_list=['sqft_living'],\n",
    "                        deg=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS:  What is the best value for the L2 penalty according to 10-fold validation?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may find it useful to plot the k-fold cross-validation errors you have obtained to better understand the behavior of the method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the l2_penalty values in the x axis and the cross-validation error in the y axis.\n",
    "# Using plt.xscale('log') will make your plot more intuitive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you found the best value for the L2 penalty using cross-validation, it is important to retrain a final model on all of the training data using this value of `l2_penalty`. This way, your final model will be trained on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION: Using the best L2 penalty found above, train a model using all training data. What is the RSS on the TEST data of the model you learn with this L2 penalty? ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit480b74ee098b4c469210f9ea89f2997c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}